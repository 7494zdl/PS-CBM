#We reduce the CIFAR10 dataset by ten times for a toy

python run_train.py --dataset CIFAR10 --backbone "clip_RN50" --save_dir "save_model" --concept_set "data/generate_concept/concept/CIFAR10_concepts_gpt-4o_final.json" --Tmerge 0.9996 --Tconf 0.20 --lam 0.0007 --n_iters 10000 --saga_batch_size 256 --cbl_layer_num 2 --cbl_bias --use_penultimate --cbl_batch_size 1024 --cbl_lr 0.0004 --cbl_steps 20000 --weight_decay 0 --K_indep 5