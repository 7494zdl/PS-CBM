{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac1c143-4927-43b1-85fe-1638f9a25975",
   "metadata": {},
   "source": [
    "#  Partially Shared Concept Bottleneck Models (PS-CBM)\n",
    "This is the official repository for our paper \"Partially Shared Concept Bottleneck Models\".\n",
    "\n",
    "PS-CBM is a framework that introduces a partially shared concept strategy to reduce redundancy while preserving discrimination. It achieves stateâ€‘ofâ€‘theâ€‘art accuracy using significantly fewer concepts.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"figures/overview.png\" alt=\"PS-CBM Overview\" width=\"90%\">\n",
    "</div>\n",
    "\n",
    "## âš™ï¸ Setup Environment\n",
    "We run our experiments using Python 3.9.23. To set up the environment:\n",
    "```\n",
    "# Create a new conda environment\n",
    "conda create --name pscbm python=3.9.23\n",
    "\n",
    "# Activate the environment\n",
    "conda activate pscbm\n",
    "\n",
    "# Install required Python packages\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "\n",
    "## ğŸ“‚ Dataset\n",
    "\n",
    "All datasets should be placed under the `dataset/` directory.\n",
    "\n",
    "### Dataset Structure\n",
    "\n",
    "```\n",
    "dataset/\n",
    "â””â”€â”€ <dataset_name>/\n",
    "    â”œâ”€â”€ <dataset_name>_train/\n",
    "    â”‚   â”œâ”€â”€ <class_1>/\n",
    "    â”‚   â”œâ”€â”€ <class_2>/\n",
    "    â”‚   â””â”€â”€ ...\n",
    "    â”œâ”€â”€ <dataset_name>_val/\n",
    "    â”‚   â”œâ”€â”€ <class_1>/\n",
    "    â”‚   â”œâ”€â”€ <class_2>/\n",
    "    â”‚   â””â”€â”€ ...\n",
    "    â”œâ”€â”€ <dataset_name>_test/\n",
    "    â”‚   â”œâ”€â”€ <class_1>/\n",
    "    â”‚   â”œâ”€â”€ <class_2>/\n",
    "    â”‚   â””â”€â”€ ...\n",
    "    â””â”€â”€ splits/\n",
    "```\n",
    "\n",
    "> **Note:** The class folder order in each of the train/val/test directories **must** match the sequence in  \n",
    "> `data/classes_name/dataset_classes.txt`.\n",
    "\n",
    "---\n",
    "\n",
    "### Dataset Download\n",
    "\n",
    "| Dataset       | Download Link                                                                                                              |\n",
    "|---------------|----------------------------------------------------------------------------------------------------------------------------|\n",
    "| Aircraft      | https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/archives/fgvc-aircraft-2013b.tar.gz                                    |\n",
    "| CIFAR10       | https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz                                                                    |\n",
    "| CIFAR100      | https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz                                                                   |\n",
    "| CUB200        | https://data.caltech.edu/records/20098                                                                                     |\n",
    "| DTD           | https://www.robots.ox.ac.uk/~vgg/data/dtd/download/dtd-r1.0.1.tar.gz                                                       |\n",
    "| Flowers102    | https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz                                                           |\n",
    "| Food101       | http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz                                                                          |\n",
    "| HAM10000      | https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T#                                           |\n",
    "| ImageNet      | https://image-net.org/index.php                                                                                            |\n",
    "| RESISC45      | https://1drv.ms/u/s!AmgKYzARBl5ca3HNaHIlzp_IXjs                                                                            |\n",
    "| UCF101        | https://drive.google.com/file/d/10Jqome3vtUA2keJkNanAiFpgbyC9Hc2O/view?usp=sharing                                         |\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ—‚ï¸ Directories\n",
    "\n",
    "Below is an overview of the key directories and files in this project:\n",
    "\n",
    "### Main Directories\n",
    "\n",
    "```\n",
    "data/\n",
    "â”œâ”€â”€ classes_name/         # Contains dataset-specific class name files (e.g., dataset_name_classes.txt)\n",
    "â”œâ”€â”€ generate_concept/     # Stores generated concept JSON files\n",
    "â””â”€â”€ selected_image/       # Stores selected few-shot exemplar images\n",
    "\n",
    "dataset/                  # Contains downloaded datasets and split files\n",
    "                          # You must reorganize datasets using split files and class order files manually\n",
    "                          # We provide a toy version of CIFAR-10 (1/10 sampling) in dataset/CIFAR10\n",
    "\n",
    "model/                    # Contains model implementation\n",
    "\n",
    "save_model/               # Stores trained model checkpoints\n",
    "```\n",
    "\n",
    "### Other Files\n",
    "\n",
    "- `data_utils.py`, `utils_my.py`: Data loading, processing utilities, and core logic for the **Partially Shared Concept Strategy**\n",
    "- `run_train.py`, `run_train_on_imagenet.py`: Scripts for training, evaluating, and saving models  \n",
    "  *(Note: Due to ImageNetâ€™s scale, custom loading strategies are used to reduce resource demands.)*\n",
    "- `select_image.ipynb`: Select exemplars from training images\n",
    "- `generate_concept.ipynb`: Generate concept JSON files\n",
    "- `run_commands.txt`, `run_commands_toyDataset.txt`: Shell command templates for training  \n",
    "  *(We recommend starting with `run_commands_toyDataset.txt` on the toy CIFAR-10 dataset for quick tests.)*\n",
    "\n",
    "\n",
    "\n",
    "## ğŸš€ Pipeline\n",
    "Follow the steps below to train and evaluate the PS-CBM model.\n",
    "\n",
    "### 1. Creating Concept Sets (Optional)\n",
    "\n",
    ">This step is optional because we have already provided pre-generated concept files for each dataset in the `data/generate_concept/concept/` directory. You can directly use them without running these notebooks.\n",
    "\n",
    "Run the following notebooks to generate your concept set:\n",
    "If you wish to create your own concept sets (e.g., with different exemplars or criteria), you can run the following notebooks:\n",
    "```\n",
    "# Select exemplar images from the training set\n",
    "select_image.ipynb\n",
    "\n",
    "# Generate concept JSON files from selected exemplars\n",
    "generate_concept.ipynb\n",
    "```\n",
    "\n",
    "### 2. Training, Testing, and Saving the PS-CBM Model\n",
    "Use the commands provided in run_commands.txt.\n",
    "\n",
    "Example command:\n",
    "```\n",
    "python run_train.py \\\\\n",
    "  --dataset CIFAR10 \\\\\n",
    "  --backbone \"clip_RN50\" \\\\\n",
    "  --save_dir \"save_model\" \\\\\n",
    "  --concept_set \"data/generate_concept/concept/CIFAR10_concepts_gpt-4o_final.json\" \\\\\n",
    "  --Tmerge 0.9996 \\\\\n",
    "  --Tconf 0.20 \\\\\n",
    "  --lam 0.0007 \\\\\n",
    "  --n_iters 10000 \\\\\n",
    "  --saga_batch_size 256 \\\\\n",
    "  --cbl_layer_num 2 \\\\\n",
    "  --cbl_bias \\\\\n",
    "  --use_penultimate \\\\\n",
    "  --cbl_batch_size 1024 \\\\\n",
    "  --cbl_lr 0.0004 \\\\\n",
    "  --cbl_steps 20000 \\\\\n",
    "  --weight_decay 0 \\\\\n",
    "  --K_indep 5\n",
    "  ```\n",
    "\n",
    "  You can modify the command parameters in run_commands.txt or use run_commands_toyDataset.txt for quick testing on the toy CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8f0cd7-744f-4a6e-8b47-85fb6263374d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ourCBM",
   "language": "python",
   "name": "ourcbm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
