{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f42b71-01da-4b9a-9220-6da795eacce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] airplane: ['cockpit windows', 'engines under wings', 'horizontal stabilizer', 'horizontal stabilizers', 'landing gear', 'long fuselage', 'rounded nose', 'tail fin', 'turbine engines', 'two wings', 'vertical tail', 'white body']\n",
      "[✓] automobile: ['body paint', 'door handles', 'exhaust pipe', 'four wheels', 'front grille', 'glass windows', 'grille', 'headlights', 'license plate', 'logo badge', 'metallic body', 'rearview mirrors', 'rectangular shape', 'rubber tires', 'side doors', 'side mirrors', 'tires', 'wheels', 'windshield']\n",
      "[✓] bird: ['Brownish or gray tones', 'a beak', 'a tail', 'feathered body', 'pointed beak', 'rounded body', 'small feathers', 'two legs', 'two wings']\n",
      "[✓] cat: ['cat ears', 'four legs', 'furry body', 'furry coat', 'large eyes', 'long tail', 'round ears', 'small nose', 'unique fur patterns', 'vertical pupils', 'whiskers']\n",
      "[✓] deer: ['antlers', 'brown fur', 'brown fur coat', 'four legs', 'grassy background', 'large branching antlers', 'pointed ears', 'prominent eyes', 'reflective water surface']\n",
      "[✓] dog: ['a snout', 'a wagging tail', 'brown or white coat', 'dark eyes', 'floppy ears', 'four legs', 'fur texture', 'long tail', 'pointed ears', 'wet nose']\n",
      "[✓] frog: ['bulging eyes', 'green or brown color', 'rounded body', 'short limbs', 'smooth skin', 'webbed feet', 'wide mouth']\n",
      "[✓] horse: ['arched neck', 'dark mane and tail', 'four hooves', 'four legs', 'hooves', 'large curved neck', 'long face', 'long mane', 'long muscular legs', 'pointed ears', 'smooth torso', 'wide forehead']\n",
      "[✓] ship: ['a large deck', 'a narrow hull', 'a tall mast', 'boats with pointed bows', 'decks and cabins', 'floating on water', 'horizontal hulls', 'metallic structures', 'sails or masts', 'wakes in water']\n",
      "[✓] truck: ['angular body shape', 'boxy shape', 'bright headlights', 'cargo area', 'cargo markings or logos', 'exhaust pipe', 'extended cargo area', 'four wheels', 'front grille', 'headlights', 'heavy-duty tires', 'large enclosed cab', 'large front bumper', 'large wheels', 'lift or crane attachments', 'long chassis', 'prominent grille', 'rearview windows', 'side mirrors', 'visible cab']\n",
      "\n",
      " Save in ./data/generate_concept/concept/CIFAR10_concepts_gpt-4o_init.json\n",
      "[✓] JSON Save in ：./data/generate_concept/concept/CIFAR10_concepts_gpt-4o_ordered.json\n",
      "[✓] Save in ：./data/generate_concept/concept/CIFAR10_concepts_gpt-4o_final.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from typing import List, Dict, Any\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "dataset_name = \"CIFAR10\"\n",
    "max_images = 8\n",
    "MAX_LEN = 35\n",
    "gpt_model = \"gpt-4o\"\n",
    "\n",
    "root_dir = f\"./data/selected_image/{dataset_name}\"\n",
    "concept_output_path = f\"./data/generate_concept/concept/{dataset_name}_concepts_\"+gpt_model+\"_init.json\"\n",
    "ordered_output_path = f\"./data/generate_concept/concept/{dataset_name}_concepts_\"+gpt_model+\"_ordered.json\"\n",
    "kv_output_path = f\"./data/generate_concept/concept/{dataset_name}_concepts_\"+gpt_model+\"_final.json\"\n",
    "class_list_path = f\"./data/classes_name/{dataset_name}_classes.txt\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"\",#your base_url\n",
    "    api_key=\"\",#your api_key\n",
    ")\n",
    "\n",
    "\n",
    "def clean_readable_name(class_name: str) -> str:\n",
    "    name = re.sub(r'^\\d+\\.', '', class_name)\n",
    "    return name.replace('_', ' ').strip()\n",
    "\n",
    "def encode_image(image_path: str) -> str:\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "def build_prompt(readable_name: str, dataset_name: str) -> List[Dict]:\n",
    "    return [{\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \n",
    "        f\"\"\"\n",
    "        You are shown several sample images from \"{readable_name}\".\n",
    "        \n",
    "        Examine their visual patterns and summarize the key features that commonly define this category in its image domain.\n",
    "        Please focus on traits that are typically present across most samples, even if not in every image. \n",
    "        Describe each feature as a short, concrete visual concept without abstraction or inference. \n",
    "        Ensure that each concept is concise (≤30 characters) and output as a plain list without numbering or full sentences.\n",
    "            \n",
    "        Output format example:\n",
    "        -two wings\n",
    "        -a black cap\n",
    "        -long gray runways\n",
    "        -a baseball\n",
    "        -a pattern of spots\n",
    "        \n",
    "        Now generate the feature list:\n",
    "        \"\"\"\n",
    "    }]\n",
    "\n",
    "def generate_concepts():\n",
    "    all_concepts = {}\n",
    "    class_names = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "\n",
    "    for class_name in sorted(class_names):\n",
    "        image_dir = os.path.join(root_dir, class_name)\n",
    "        image_files = sorted(os.listdir(image_dir))[:max_images]\n",
    "\n",
    "        if not image_files:\n",
    "            continue\n",
    "\n",
    "        readable_name = clean_readable_name(class_name)\n",
    "        all_responses = []\n",
    "\n",
    "        for split in [0, 1]: \n",
    "            split_len = len(image_files) // 2\n",
    "            split_files = image_files[split * split_len : (split + 1) * split_len]\n",
    "\n",
    "            message_content = build_prompt(readable_name, dataset_name)\n",
    "            for image_file in split_files:\n",
    "                image_path = os.path.join(image_dir, image_file)\n",
    "                base64_img = encode_image(image_path)\n",
    "                message_content.append({\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_img}\"}\n",
    "                })\n",
    "\n",
    "            try:\n",
    "                completion = client.chat.completions.create(\n",
    "                    model=gpt_model,\n",
    "                    messages=[{\"role\": \"user\", \"content\": message_content}],\n",
    "                )\n",
    "                raw_output = completion.choices[0].message.content\n",
    "                concept_list = [\n",
    "                    line.strip(\"•-1234567890. \").strip()\n",
    "                    for line in raw_output.strip().split('\\n')\n",
    "                    if line.strip()\n",
    "                ]\n",
    "                concept_list = [c for c in concept_list if len(c) <= MAX_LEN]\n",
    "                all_responses.extend(concept_list)\n",
    "            except Exception as e:\n",
    "                print(f\"[✗] Failed on {class_name} (split {split+1}): {e}\")\n",
    "\n",
    "        unique_concepts = sorted(set(all_responses))\n",
    "        all_concepts[readable_name] = unique_concepts\n",
    "        print(f\"[✓] {readable_name}: {unique_concepts}\")\n",
    "\n",
    "    with open(concept_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_concepts, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n Save in {concept_output_path}\")\n",
    "\n",
    "def reorder_by_class_list():\n",
    "    with open(class_list_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        ordered_classes = [line.strip().replace('_', ' ') for line in f if line.strip()]\n",
    "    with open(concept_output_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    ordered_data = OrderedDict()\n",
    "    for cls in ordered_classes:\n",
    "        if cls in data:\n",
    "            ordered_data[cls] = data[cls]\n",
    "\n",
    "    with open(ordered_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(ordered_data, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"[✓] JSON Save in ：{ordered_output_path}\")\n",
    "\n",
    "def convert_to_key_value_lists(input_path: str) -> Dict[str, List[Any]]:\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    value_list = []\n",
    "    key_list = []\n",
    "    for i, (key, values) in enumerate(data.items()):\n",
    "        for val in values:\n",
    "            value_list.append(val)\n",
    "            key_list.append(i)\n",
    "    return {\"concepts\": value_list, \"concepts_to_class\": key_list}\n",
    "\n",
    "def save_key_value_format():\n",
    "    output = convert_to_key_value_lists(ordered_output_path)\n",
    "    with open(kv_output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"[✓] Save in ：{kv_output_path}\")\n",
    "if __name__ == \"__main__\":\n",
    "    generate_concepts()\n",
    "    reorder_by_class_list()\n",
    "    save_key_value_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc6658c-05c6-4546-9c3f-5d250159a103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ourCBM",
   "language": "python",
   "name": "ourcbm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
